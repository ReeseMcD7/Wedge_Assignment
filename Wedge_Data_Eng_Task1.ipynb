{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1354880d",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Task 1: Cleaning the Wedge transaction data files and uploading them to GBQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7197954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import datetime \n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_gbq\n",
    "import janitor\n",
    "import shutil\n",
    "import glob\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee7233",
   "metadata": {},
   "source": [
    "This next section of cells is necessary to generate lists of delimiters and headers for use later on in the code in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "224028ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates list of zip files in this directory.\n",
    "zip_files = os.listdir(\"WedgeZipOfZips/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde42555",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like transArchive_201001_201003.csv has delimiter , .\n",
      "It looks like transArchive_201004_201006.csv has delimiter , .\n",
      "It looks like transArchive_201007_201009.csv has delimiter , .\n",
      "It looks like transArchive_201010_201012.csv has delimiter , .\n",
      "It looks like transArchive_201101_201103.csv has delimiter , .\n",
      "It looks like transArchive_201104.csv has delimiter , .\n",
      "It looks like transArchive_201105.csv has delimiter , .\n",
      "It looks like transArchive_201106.csv has delimiter , .\n",
      "It looks like transArchive_201107_201109.csv has delimiter , .\n",
      "It looks like transArchive_201110_201112.csv has delimiter , .\n",
      "It looks like transArchive_201201_201203.csv has delimiter , .\n",
      "It looks like transArchive_201201_201203_inactive.csv has delimiter ; .\n",
      "It looks like transArchive_201204_201206.csv has delimiter , .\n",
      "It looks like transArchive_201204_201206_inactive.csv has delimiter ; .\n",
      "It looks like transArchive_201207_201209.csv has delimiter , .\n",
      "It looks like transArchive_201207_201209_inactive.csv has delimiter ; .\n",
      "It looks like transArchive_201210_201212.csv has delimiter , .\n",
      "It looks like transArchive_201210_201212_inactive.csv has delimiter ; .\n",
      "It looks like transArchive_201301_201303.csv has delimiter , .\n",
      "It looks like transArchive_201301_201303_inactive.csv has delimiter ; .\n",
      "It looks like transArchive_201304_201306.csv has delimiter , .\n",
      "It looks like transArchive_201304_201306_inactive.csv has delimiter ; .\n",
      "It looks like transArchive_201307_201309.csv has delimiter , .\n",
      "It looks like transArchive_201307_201309_inactive.csv has delimiter ; .\n",
      "It looks like transArchive_201310_201312.csv has delimiter , .\n",
      "It looks like transArchive_201310_201312_inactive.csv has delimiter ; .\n",
      "It looks like transArchive_201401_201403.csv has delimiter , .\n",
      "It looks like transArchive_201401_201403_inactive.csv has delimiter ; .\n",
      "It looks like transArchive_201404_201406.csv has delimiter , .\n",
      "It looks like transArchive_201404_201406_inactive.csv has delimiter ; .\n",
      "It looks like transArchive_201407_201409.csv has delimiter , .\n",
      "It looks like transArchive_201407_201409_inactive.csv has delimiter ; .\n",
      "It looks like transArchive_201410_201412.csv has delimiter , .\n",
      "It looks like transArchive_201410_201412_inactive.csv has delimiter ; .\n",
      "It looks like transArchive_201501_201503.csv has delimiter , .\n",
      "It looks like transArchive_201504_201506.csv has delimiter , .\n",
      "It looks like transArchive_201507_201509.csv has delimiter , .\n",
      "It looks like transArchive_201510.csv has delimiter , .\n",
      "It looks like transArchive_201511.csv has delimiter , .\n",
      "It looks like transArchive_201512.csv has delimiter , .\n",
      "It looks like transArchive_201601.csv has delimiter , .\n",
      "It looks like transArchive_201602.csv has delimiter , .\n",
      "It looks like transArchive_201603.csv has delimiter , .\n",
      "It looks like transArchive_201604.csv has delimiter , .\n",
      "It looks like transArchive_201605.csv has delimiter , .\n",
      "It looks like transArchive_201606.csv has delimiter , .\n",
      "It looks like transArchive_201607.csv has delimiter , .\n",
      "It looks like transArchive_201608.csv has delimiter , .\n",
      "It looks like transArchive_201609.csv has delimiter , .\n",
      "It looks like transArchive_201610.csv has delimiter , .\n",
      "It looks like transArchive_201611.csv has delimiter , .\n",
      "It looks like transArchive_201612.csv has delimiter , .\n",
      "It looks like transArchive_201701.csv has delimiter , .\n"
     ]
    }
   ],
   "source": [
    "# Checking for delimiters\n",
    "import csv\n",
    "import io\n",
    "\n",
    "delimiters = dict() \n",
    "# r-read,w-write,a-append\n",
    "# Start by reading in all the files again.\n",
    "for this_zf in zip_files :\n",
    "    with ZipFile(\"WedgeZipOfZips/\" + this_zf,'r') as zf :\n",
    "        zipped_files = zf.namelist()\n",
    "        \n",
    "        for file_name in zipped_files :\n",
    "            input_file = zf.open(file_name,'r')\n",
    "            input_file = io.TextIOWrapper(input_file,encoding=\"utf-8\")\n",
    "            \n",
    "            dialect = csv.Sniffer().sniff(sample=input_file.readline(),\n",
    "                                      delimiters=[\",\",\";\",\"\\t\"])\n",
    "            \n",
    "            delimiters[file_name] = dialect.delimiter\n",
    "            \n",
    "            print(\" \".join([\"It looks like\",\n",
    "                           file_name,\n",
    "                           \"has delimiter\",\n",
    "                           dialect.delimiter,\n",
    "                           \".\"]))\n",
    "\n",
    "            input_file.close() # Tidy up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc415b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for headers\n",
    "headers = dict()\n",
    "\n",
    "for this_zf in zip_files :\n",
    "    with ZipFile(\"WedgeZipOfZips/\" + this_zf,'r') as zf :\n",
    "        zipped_files = zf.namelist()\n",
    "\n",
    "        for file_name in zipped_files :\n",
    "            input_file = zf.open(file_name,'r')\n",
    "            input_file = io.TextIOWrapper(input_file,encoding=\"utf-8\")\n",
    "            \n",
    "            this_delimiter = delimiters[file_name]\n",
    "            \n",
    "            for line in input_file :\n",
    "                #print(line.strip().split(this_delimiter))\n",
    "                break\n",
    "            #print(line)\n",
    "            headers[file_name] = \"datetime\" in line\n",
    "                        \n",
    "            input_file.close() # Tidy up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef234cc",
   "metadata": {},
   "source": [
    "Next, the 'Wedge_Unzipped' directory is deleted if it exists. Then we need an extraction of the original zipped data into a new directory 'Wedge_Unzipped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31ce5b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder has been deleted successfully!\n"
     ]
    }
   ],
   "source": [
    "folderPath = 'Wedge_Unzipped';\n",
    "    \n",
    "# Check if folder exists or not.\n",
    "if os.path.exists(folderPath):\n",
    "      \n",
    "    # Delete Folder.\n",
    "    shutil.rmtree(folderPath)\n",
    "  \n",
    "    print(\"The folder has been deleted successfully!\")\n",
    "else:\n",
    "    print(\"Cannot delete the folder as it doesn't exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14936002",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transArchive_201001_201003.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201004_201006.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201007_201009.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201010_201012.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201101_201103.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201104.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201105.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201106.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201107_201109.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201110_201112.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201201_201203.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201201_201203_inactive.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201204_201206.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201204_201206_inactive.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201207_201209.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201207_201209_inactive.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201210_201212.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201210_201212_inactive.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201301_201303.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201301_201303_inactive.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201304_201306.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201304_201306_inactive.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201307_201309.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201307_201309_inactive.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201310_201312.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201310_201312_inactive.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201401_201403.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201401_201403_inactive.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201404_201406.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201404_201406_inactive.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201407_201409.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201407_201409_inactive.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201410_201412.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201410_201412_inactive.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201501_201503.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201504_201506.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201507_201509.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201510.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201511.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201512.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201601.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201602.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201603.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201604.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201605.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201606.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201607.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201608.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201609.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201610.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201611.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201612.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "['transArchive_201701.csv']\n",
      "Extracting all the files now...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Extracts all zips in 'WedgeZipOfZips' to 'Wedge_Unzipped'.\n",
    "for zipf in zip_files :\n",
    "    with ZipFile(\"WedgeZipOfZips/\" + zipf,'r') as zf :  \n",
    "        print(zf.namelist())\n",
    "        \n",
    "        print('Extracting all the files now...')\n",
    "        zf.extractall('Wedge_Unzipped')\n",
    "        print('Done!')\n",
    "        #break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2bf5d0",
   "metadata": {},
   "source": [
    "Now, the files in 'Wedge_Unzipped' that do not have headers need to be moved to a new directory called 'O_Headers' after deleting this directory if it exists. The code then converts the headerless csv files to files with headers and moves them back to 'Wedge_Unzipped'. After, we clean up 'O_Headers' as it is no longer needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c99062f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot delete the folder as it doesn't exists\n"
     ]
    }
   ],
   "source": [
    "folderPath = 'O_Headers';\n",
    "    \n",
    "# Check if folder exists or not.\n",
    "if os.path.exists(folderPath):\n",
    "      \n",
    "    # Delete Folder.\n",
    "    shutil.rmtree(folderPath)\n",
    "  \n",
    "    print(\"The folder has been deleted successfully!\")\n",
    "else:\n",
    "    print(\"Cannot delete the folder as it doesn't exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af89b931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell converts the headers dictionary built earlier on into a dataframe.\n",
    "keys = []\n",
    "values = []\n",
    "\n",
    "for value in headers.values():\n",
    "    values.append(value)\n",
    "for key in headers.keys():\n",
    "    keys.append(key)\n",
    "\n",
    "# Column name list. \n",
    "col_names =  ['file', 'headers']\n",
    "  \n",
    "# Create an empty dataframe.\n",
    "# Add columns.\n",
    "headers_df  = pd.DataFrame(columns = col_names)\n",
    "headers_df.file = keys\n",
    "headers_df.headers = values\n",
    "\n",
    "# Show the dataframe.\n",
    "# headers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95eec193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts boolean to float.\n",
    "headers_df['headers'] = headers_df['headers'].astype(float)\n",
    "# headers_df['headers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "469d011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates list of files with no headers.\n",
    "headless = headers_df[(headers_df.headers == 0)]\n",
    "headless = headless.file\n",
    "file_names_headless = []\n",
    "\n",
    "for file_name in headless :\n",
    "    file_names_headless.append(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03f0ac4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new directory is created!\n"
     ]
    }
   ],
   "source": [
    "# Creates 'O_Headers' directory.\n",
    "path = \"O_Headers\"\n",
    "# Check whether the specified path exists or not\n",
    "isExist = os.path.exists(path)\n",
    "if not isExist:\n",
    "\n",
    "   # Create a new directory because it does not exist.\n",
    "   os.makedirs(path)\n",
    "   print(\"The new directory is created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2458a14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved: transArchive_201511.csv\n",
      "Moved: transArchive_201512.csv\n",
      "Moved: transArchive_201601.csv\n",
      "Moved: transArchive_201602.csv\n",
      "Moved: transArchive_201603.csv\n",
      "Moved: transArchive_201604.csv\n",
      "Moved: transArchive_201605.csv\n",
      "Moved: transArchive_201606.csv\n",
      "Moved: transArchive_201607.csv\n",
      "Moved: transArchive_201608.csv\n",
      "Moved: transArchive_201609.csv\n",
      "Moved: transArchive_201610.csv\n",
      "Moved: transArchive_201611.csv\n",
      "Moved: transArchive_201612.csv\n",
      "Moved: transArchive_201701.csv\n"
     ]
    }
   ],
   "source": [
    "# Moves files with no headers to 'O_Headers'.\n",
    "source_folder = r\"Wedge_Unzipped\\\\\"\n",
    "destination_folder = r\"O_Headers\\\\\"\n",
    "files_to_move = file_names_headless\n",
    "\n",
    "for file in files_to_move:\n",
    "    # Construct full file path.\n",
    "    source = source_folder + file\n",
    "    destination = destination_folder + file\n",
    "    # Move files.\n",
    "    shutil.move(source, destination)\n",
    "    print('Moved:', file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8229ac54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\343021690.py:6: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_heads = pd.read_csv('O_headers\\\\'+headless, header = None)\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\343021690.py:6: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_heads = pd.read_csv('O_headers\\\\'+headless, header = None)\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\343021690.py:6: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_heads = pd.read_csv('O_headers\\\\'+headless, header = None)\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\343021690.py:6: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_heads = pd.read_csv('O_headers\\\\'+headless, header = None)\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\343021690.py:6: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_heads = pd.read_csv('O_headers\\\\'+headless, header = None)\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\343021690.py:6: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_heads = pd.read_csv('O_headers\\\\'+headless, header = None)\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\343021690.py:6: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_heads = pd.read_csv('O_headers\\\\'+headless, header = None)\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\343021690.py:6: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_heads = pd.read_csv('O_headers\\\\'+headless, header = None)\n"
     ]
    }
   ],
   "source": [
    "# Reads headless list to df and then back to csv with specified headers to 'Wedge_Unzipped'.\n",
    "headless_list = os.listdir(\"O_Headers\")\n",
    "\n",
    "# Read csv file to a DataFrame.\n",
    "for headless in headless_list :\n",
    "    big_heads = pd.read_csv('O_headers\\\\'+headless, header = None)\n",
    "    \n",
    "    # Write DataFrame to csv file, but with header.\n",
    "for headless in headless_list :\n",
    "    path = 'Wedge_Unzipped\\\\'\n",
    "    big_heads.to_csv(\n",
    "        path + headless,\n",
    "        header=[\"datetime\",\"register_no\",\"emp_no\",\"trans_no\",\"upc\",\"description\",\"trans_type\",\"trans_subtype\",\"trans_status\",\"department\",\"quantity\",\"Scale\",\"cost\",\"unitPrice\",\"total\",\"regPrice\",\"altPrice\",\"tax\",\"taxexempt\",\"foodstamp\",\"wicable\",\"discount\",\"memDiscount\",\"discountable\",\"discounttype\",\"voided\",\"percentDiscount\",\"ItemQtty\",\"volDiscType\",\"volume\",\"VolSpecial\",\"mixMatch\",\"matched\",\"memType\",\"staff\",\"numflag\",\"itemstatus\",\"tenderstatus\",\"charflag\",\"varflag\",\"batchHeaderID\",\"local\",\"organic\",\"display\",\"receipt\",\"card_no\",\"store\",\"branch\",\"match_id\",\"trans_id\"],\n",
    "        index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9b86555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder has been deleted successfully!\n"
     ]
    }
   ],
   "source": [
    "# Deletes now useless 'O_Headers' directory.\n",
    "folderPath = 'O_Headers';\n",
    "    \n",
    "# Check if folder exists or not.\n",
    "if os.path.exists(folderPath):\n",
    "      \n",
    "    # Deletes folder.\n",
    "    shutil.rmtree(folderPath)\n",
    "  \n",
    "    print(\"The folder has been deleted successfully!\")\n",
    "else:\n",
    "    print(\"Cannot delete the folder as it doesn't exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb81be5",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we need to upload the data to GBQ after establishing a connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79551e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the private key.\n",
    "service_path = \"C:\\\\Users\\\\rsmcd\\\\OneDrive\\\\Desktop\\\\MSBA Fall 2022\\\\\" # Path to json file.\n",
    "service_file = 'reese-msba-9558fdd20984.json' # Name of json file.\n",
    "gbq_proj_id = 'reese-msba' # Name of project.\n",
    "\n",
    "# Creates single variable that leads to json file.\n",
    "private_key =service_path + service_file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "473de799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we pass in our credentials so that Python has permission to access our project.\n",
    "credentials = service_account.Credentials.from_service_account_file(service_path + service_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f10cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And finally we establish our connection.\n",
    "client = bigquery.Client(credentials = credentials, project=gbq_proj_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1b244db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reese-msba:dram_shop\n",
      "reese-msba:wedge_transactions\n"
     ]
    }
   ],
   "source": [
    "# Look at list of data sets in client.\n",
    "for item in client.list_datasets() : \n",
    "    print(item.full_dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238c8e2b",
   "metadata": {},
   "source": [
    "This body of code cleans up the files and uploads to GBQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24b31536",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1003.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (33,42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (33,42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1004.62it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (33,42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (33,42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (33,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (33,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (33,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1002.94it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_28360\\2273625615.py:7: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "gbq_proj_id = 'reese-msba'\n",
    "dataset_id = 'wedge_transactions'\n",
    "unzipped_files = os.listdir(\"Wedge_Unzipped\")\n",
    "\n",
    "for uz_file in unzipped_files :\n",
    "    \n",
    "    big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") # Reads in files to big_wedge using file specific delimiters.\n",
    "    big_wedge = big_wedge.replace(r'\\N', np.nan).replace(r' ', np.nan) # Replaces all \\N and ' ' with gbq ready null values.\n",
    "    for idx, column in enumerate(big_wedge) : \n",
    "        if big_wedge[column].dtypes == object : # Converts all object columns to strings and replaces 'nan' with gbq ready null values.\n",
    "            big_wedge = big_wedge.astype({column :'str'}).replace('nan', np.nan)\n",
    "        if big_wedge[column].dtypes == \"int64\" : # Converts all integer columns to floats.\n",
    "            big_wedge = big_wedge.astype({column :'float'})\n",
    "    big_wedge['datetime'] = pd.to_datetime(big_wedge['datetime']) # Converts datetime columns to timestamp.\n",
    "    cols = ['wicable','taxexempt','percentDiscount','receipt','match_id','local','organic','itemstatus','tenderstatus'] # List of columns to convert to float.\n",
    "    for idx, col in enumerate(cols) :\n",
    "        big_wedge[col] = pd.to_numeric(big_wedge[col]) # Converts cols to float.\n",
    "    cols2 = ['memType','staff','batchHeaderID','display'] # List of columns to convert to boolean.\n",
    "    for idx, col in enumerate(cols2) :\n",
    "        big_wedge[col] = big_wedge[col].map({1:True, 0:False}).astype('boolean') # Maps 1 and 0 to True and False, then converts to boolean while preserving null values.\n",
    "#     break\n",
    "\n",
    "# Uploads all to GBQ.\n",
    "    table_name, _ = uz_file.split(\".\")\n",
    "    table_id = \".\".join([gbq_proj_id,dataset_id,table_name])\n",
    "    pandas_gbq.to_gbq(big_wedge, table_id, project_id=gbq_proj_id,if_exists=\"replace\")\n",
    "#     break    \n",
    "\n",
    "## Should wicable, taxexempt, & local be boolean?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
